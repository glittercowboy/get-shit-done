---
phase: 04-knowledge-extraction-hooks
plan: 03
type: execute
wave: 2
depends_on: ["04-01", "04-02"]
files_modified:
  - get-shit-done/bin/knowledge-dedup.js
  - get-shit-done/bin/knowledge-evolution.js
autonomous: true

must_haves:
  truths:
    - "Three-stage deduplication: content hash -> canonical hash -> embedding similarity"
    - "Exact duplicates (>0.88 similarity) are rejected"
    - "Similar content (0.65-0.88) triggers memory evolution"
    - "Dissimilar content (<0.65) creates new entries"
    - "Memory evolution appends updates, preserves original"
  artifacts:
    - path: "get-shit-done/bin/knowledge-dedup.js"
      provides: "Three-stage deduplication"
      exports: ["checkDuplicate", "findSimilarByEmbedding"]
    - path: "get-shit-done/bin/knowledge-evolution.js"
      provides: "Memory evolution logic"
      exports: ["insertOrEvolve", "mergeMemories"]
  key_links:
    - from: "get-shit-done/bin/knowledge-dedup.js"
      to: "get-shit-done/bin/embeddings.js"
      via: "embedding comparison"
      pattern: "generateEmbedding|findSimilarByEmbedding"
    - from: "get-shit-done/bin/knowledge-evolution.js"
      to: "get-shit-done/bin/knowledge-crud.js"
      via: "update operations"
      pattern: "updateKnowledge|insertKnowledge"
---

<objective>
Implement three-stage deduplication and memory evolution for intelligent knowledge management

Purpose: Prevent duplicate memories (KNOW-16) and evolve existing memories when similar content arrives (KNOW-17)
Output: knowledge-dedup.js for duplicate detection, knowledge-evolution.js for update-vs-create logic
</objective>

<execution_context>
@/Users/ollorin/.claude/get-shit-done/workflows/execute-plan.md
@/Users/ollorin/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/04-knowledge-extraction-hooks/04-RESEARCH.md

# Phase 3 knowledge modules
@get-shit-done/bin/knowledge-crud.js
@get-shit-done/bin/knowledge-search.js
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create three-stage deduplication module</name>
  <files>get-shit-done/bin/knowledge-dedup.js</files>
  <action>
Create `get-shit-done/bin/knowledge-dedup.js` implementing KNOW-16:

**Hash-based stages (1 and 2):**
```javascript
const crypto = require('crypto');

// Thresholds from research (04-RESEARCH.md)
const DEDUP_THRESHOLDS = {
  exact: 1.0,           // Stage 1: content hash
  canonical: 0.95,      // Stage 2: canonical hash
  embedding: 0.88       // Stage 3: vector similarity
};

function computeContentHash(content) {
  return crypto.createHash('sha256').update(content.trim()).digest('hex');
}

function computeCanonicalHash(content) {
  const canonical = content
    .toLowerCase()
    .replace(/\s+/g, ' ')
    .replace(/[.,;:!?'"]/g, '')
    .trim();
  return crypto.createHash('sha256').update(canonical).digest('hex');
}

// Stage 1: Exact content match
function checkExactDuplicate(db, content) {
  const hash = computeContentHash(content);
  const existing = db.prepare(
    'SELECT id, content FROM knowledge WHERE content_hash = ?'
  ).get(hash);

  if (existing) {
    return {
      isDuplicate: true,
      stage: 'exact',
      existingId: existing.id,
      existingContent: existing.content,
      similarity: 1.0
    };
  }

  return { isDuplicate: false, contentHash: hash };
}

// Stage 2: Canonical match (normalized)
function checkCanonicalDuplicate(db, content) {
  const canonical = computeCanonicalHash(content);

  // Store canonical_hash in metadata, so we query via json_extract
  const matches = db.prepare(`
    SELECT id, content, metadata
    FROM knowledge
    WHERE json_extract(metadata, '$.canonical_hash') = ?
  `).all(canonical);

  if (matches.length > 0) {
    return {
      isDuplicate: true,
      stage: 'canonical',
      existingId: matches[0].id,
      existingContent: matches[0].content,
      similarity: 0.95
    };
  }

  return { isDuplicate: false, canonicalHash: canonical };
}
```

**Stage 3: Embedding similarity:**
```javascript
// Stage 3: Embedding-based similarity (using Phase 3 vector search)
async function findSimilarByEmbedding(conn, embedding, options = {}) {
  const { threshold = 0.88, limit = 5 } = options;

  if (!embedding || !conn.vectorEnabled) {
    return [];
  }

  const { db } = conn;

  // sqlite-vec uses distance (0 = identical, 2 = opposite for cosine)
  // Convert similarity threshold to distance: distance = 2 * (1 - similarity)
  const maxDistance = 2 * (1 - threshold);

  try {
    // Query vec0 table with k parameter
    const k = limit * 2;  // Fetch extra to account for filtering
    const results = db.prepare(`
      SELECT
        k.id,
        k.content,
        k.type,
        k.metadata,
        v.distance
      FROM knowledge_vec v
      JOIN knowledge k ON v.rowid = k.id
      WHERE v.embedding MATCH ? AND k = ?
      ORDER BY v.distance
      LIMIT ?
    `).all(embedding, k, limit);

    // Filter by threshold and convert distance to similarity
    return results
      .filter(r => r.distance <= maxDistance)
      .map(r => ({
        id: r.id,
        content: r.content,
        type: r.type,
        metadata: r.metadata ? JSON.parse(r.metadata) : {},
        distance: r.distance,
        similarity: 1 - (r.distance / 2)  // Convert cosine distance to similarity
      }));
  } catch (err) {
    console.warn('[dedup] Vector search failed:', err.message);
    return [];
  }
}

async function checkEmbeddingDuplicate(conn, embedding, threshold = 0.88) {
  const similar = await findSimilarByEmbedding(conn, embedding, { threshold, limit: 1 });

  if (similar.length > 0) {
    return {
      isDuplicate: true,
      stage: 'embedding',
      existingId: similar[0].id,
      existingContent: similar[0].content,
      similarity: similar[0].similarity,
      distance: similar[0].distance
    };
  }

  return { isDuplicate: false };
}
```

**Combined three-stage check:**
```javascript
async function checkDuplicate(conn, content, embedding = null) {
  const { db } = conn;

  // Stage 1: Exact content hash
  const exactCheck = checkExactDuplicate(db, content);
  if (exactCheck.isDuplicate) {
    return exactCheck;
  }

  // Stage 2: Canonical hash
  const canonicalCheck = checkCanonicalDuplicate(db, content);
  if (canonicalCheck.isDuplicate) {
    return canonicalCheck;
  }

  // Stage 3: Embedding similarity (if embedding provided)
  if (embedding && conn.vectorEnabled) {
    const embeddingCheck = await checkEmbeddingDuplicate(conn, embedding);
    if (embeddingCheck.isDuplicate) {
      return embeddingCheck;
    }
  }

  // Not a duplicate
  return {
    isDuplicate: false,
    contentHash: exactCheck.contentHash,
    canonicalHash: canonicalCheck.canonicalHash
  };
}
```

**Exports:**
- DEDUP_THRESHOLDS
- computeContentHash(content) -> string
- computeCanonicalHash(content) -> string
- checkExactDuplicate(db, content) -> DupResult
- checkCanonicalDuplicate(db, content) -> DupResult
- findSimilarByEmbedding(conn, embedding, options?) -> Similar[]
- checkEmbeddingDuplicate(conn, embedding, threshold?) -> DupResult
- checkDuplicate(conn, content, embedding?) -> DupResult
  </action>
  <verify>
```bash
cd get-shit-done && node -e "
const { checkDuplicate, computeContentHash, computeCanonicalHash, DEDUP_THRESHOLDS } = require('./bin/knowledge-dedup.js');

console.log('Thresholds:', DEDUP_THRESHOLDS);
console.log('Content hash:', computeContentHash('test').slice(0, 16));
console.log('Canonical same:', computeCanonicalHash('Use SQLite') === computeCanonicalHash('use sqlite!'));

// Note: Full checkDuplicate test requires database connection
console.log('\\nModule loaded successfully');
"
```
  </verify>
  <done>
- Three stages implemented: exact hash, canonical hash, embedding similarity
- checkDuplicate returns { isDuplicate, stage, existingId, similarity }
- Thresholds: exact=1.0, canonical=0.95, embedding=0.88
  </done>
</task>

<task type="auto">
  <name>Task 2: Create memory evolution module</name>
  <files>get-shit-done/bin/knowledge-evolution.js</files>
  <action>
Create `get-shit-done/bin/knowledge-evolution.js` implementing KNOW-17:

**Similarity ranges from research:**
```javascript
const EVOLUTION_THRESHOLDS = {
  duplicate: 0.88,    // > 0.88: exact duplicate, skip
  evolve_max: 0.88,   // <= 0.88: candidate for evolution
  evolve_min: 0.65,   // >= 0.65: evolve existing memory
  create: 0.65        // < 0.65: create new entry
};
```

**Memory merging strategy:**
```javascript
function mergeMemories(existing, newContent, options = {}) {
  const { separator = '\n\nUpdate: ' } = options;

  // Append new content with timestamp
  const timestamp = new Date().toISOString().split('T')[0];  // YYYY-MM-DD
  const merged = `${existing.content}${separator}[${timestamp}] ${newContent}`;

  // Update metadata with evolution tracking
  const existingMeta = existing.metadata || {};
  const evolutionCount = (existingMeta.evolution_count || 0) + 1;

  const metadata = {
    ...existingMeta,
    evolution_count: evolutionCount,
    last_evolution: Date.now(),
    evolution_history: [
      ...(existingMeta.evolution_history || []),
      {
        date: timestamp,
        content_preview: newContent.slice(0, 100),
        similarity: options.similarity
      }
    ].slice(-10)  // Keep last 10 evolutions
  };

  return { merged, metadata, evolutionCount };
}
```

**Evolution decision logic:**
```javascript
const { checkDuplicate, findSimilarByEmbedding } = require('./knowledge-dedup.js');
const { updateKnowledge, insertKnowledge } = require('./knowledge-crud.js');

async function insertOrEvolve(conn, entry, options = {}) {
  const { content, type, scope, embedding, metadata = {} } = entry;
  const { db } = conn;

  // Step 1: Check for duplicates
  const dupCheck = await checkDuplicate(conn, content, embedding);

  // Case 1: Exact duplicate (> 0.88) - skip
  if (dupCheck.isDuplicate && dupCheck.similarity > EVOLUTION_THRESHOLDS.duplicate) {
    return {
      action: 'skipped',
      reason: `duplicate_${dupCheck.stage}`,
      existingId: dupCheck.existingId,
      similarity: dupCheck.similarity
    };
  }

  // Case 2: Similar (0.65-0.88) - evolve existing
  if (dupCheck.isDuplicate &&
      dupCheck.similarity >= EVOLUTION_THRESHOLDS.evolve_min &&
      dupCheck.similarity <= EVOLUTION_THRESHOLDS.evolve_max) {

    const existing = db.prepare('SELECT * FROM knowledge WHERE id = ?').get(dupCheck.existingId);
    if (!existing) {
      // Shouldn't happen, but fallback to create
      return insertOrEvolve(conn, entry, { ...options, forceCreate: true });
    }

    // Merge memories
    const existingMeta = existing.metadata ? JSON.parse(existing.metadata) : {};
    const { merged, metadata: newMeta, evolutionCount } = mergeMemories(
      { content: existing.content, metadata: existingMeta },
      content,
      { similarity: dupCheck.similarity }
    );

    // Update existing entry
    await updateKnowledge(db, dupCheck.existingId, {
      content: merged,
      metadata: {
        ...newMeta,
        canonical_hash: dupCheck.canonicalHash || existingMeta.canonical_hash
      }
    });

    // Note: Embedding update not supported in sqlite-vec 0.1.6
    // The existing embedding stays (represents original concept)

    return {
      action: 'evolved',
      id: dupCheck.existingId,
      similarity: dupCheck.similarity,
      evolutionCount
    };
  }

  // Case 3: Different enough (< 0.65 or no match) - create new
  const canonicalHash = dupCheck.canonicalHash ||
    require('./knowledge-dedup.js').computeCanonicalHash(content);

  const result = await insertKnowledge(db, {
    content,
    type,
    scope,
    embedding,
    metadata: {
      ...metadata,
      canonical_hash: canonicalHash
    }
  });

  return {
    action: 'created',
    id: result.id,
    contentHash: result.content_hash,
    similarity: dupCheck.similarity || 0
  };
}
```

**Batch processing:**
```javascript
async function processExtractionBatch(conn, extractions, options = {}) {
  const { generateEmbedding } = require('./embeddings.js');
  const results = { created: 0, evolved: 0, skipped: 0, errors: [] };

  for (const ext of extractions) {
    try {
      // Generate embedding if not provided
      const embedding = ext.embedding || await generateEmbedding(ext.content);

      const result = await insertOrEvolve(conn, {
        content: ext.content,
        type: ext.type,
        scope: options.scope || 'project',
        embedding,
        metadata: {
          source: options.source || 'extraction',
          pattern: ext.pattern,
          extracted_at: Date.now()
        }
      });

      results[result.action]++;
    } catch (err) {
      results.errors.push({
        content: ext.content.slice(0, 50),
        error: err.message
      });
    }
  }

  return results;
}
```

**Exports:**
- EVOLUTION_THRESHOLDS
- mergeMemories(existing, newContent, options?) -> { merged, metadata, evolutionCount }
- insertOrEvolve(conn, entry, options?) -> { action, id?, similarity?, ... }
- processExtractionBatch(conn, extractions, options?) -> { created, evolved, skipped, errors }
  </action>
  <verify>
```bash
cd get-shit-done && node -e "
const { EVOLUTION_THRESHOLDS, mergeMemories } = require('./bin/knowledge-evolution.js');

console.log('Thresholds:', EVOLUTION_THRESHOLDS);

// Test merge
const merged = mergeMemories(
  { content: 'Use SQLite for storage', metadata: {} },
  'Also enable WAL mode for concurrency',
  { similarity: 0.75 }
);

console.log('\\nMerged content:', merged.merged.slice(0, 100));
console.log('Evolution count:', merged.evolutionCount);
console.log('Has evolution_history:', !!merged.metadata.evolution_history);
"
```
  </verify>
  <done>
- insertOrEvolve returns { action: 'created' | 'evolved' | 'skipped', ... }
- Similarity > 0.88 skips (exact duplicate)
- Similarity 0.65-0.88 evolves existing memory
- Similarity < 0.65 creates new entry
- mergeMemories preserves original content and tracks evolution history
  </done>
</task>

</tasks>

<verification>
All deduplication and evolution tests pass:
- Three stages detect duplicates at different levels
- Exact hash catches identical content
- Canonical hash catches formatting variations
- Embedding similarity catches semantic duplicates
- Memory evolution appends updates with timestamps
- Evolution history limited to 10 entries
</verification>

<success_criteria>
1. checkDuplicate implements three stages (hash, canonical, embedding)
2. Similarity > 0.88 detected as duplicate
3. Similarity 0.65-0.88 triggers evolution (update existing)
4. Similarity < 0.65 allows new creation
5. mergeMemories preserves original + appends update
6. Evolution metadata tracks count and history
7. processExtractionBatch handles multiple entries
</success_criteria>

<output>
After completion, create `.planning/phases/04-knowledge-extraction-hooks/04-03-SUMMARY.md`
</output>
