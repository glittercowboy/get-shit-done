---
phase: 11-session-end-knowledge-extraction
plan: 04
type: execute
wave: 3
depends_on: ["11-01", "11-02", "11-03"]
files_modified:
  - get-shit-done/bin/gsd-tools.js
  - get-shit-done/bin/historical-extract.js
autonomous: true

must_haves:
  truths:
    - "gsd-tools.js analyze-session command triggers Haiku analysis on a specific session JSONL file"
    - "gsd-tools.js historical-extract command reads completed phases from a project .planning/ directory and spawns sequential Haiku analysis per phase"
    - "gsd-tools.js analysis-status command reports total sessions analyzed, insights extracted, and last analysis timestamp"
    - "Historical extraction treats each completed phase as one conversation (conversation_id = phase number) per locked decision #4"
  artifacts:
    - path: "get-shit-done/bin/gsd-tools.js"
      provides: "CLI commands: analyze-session, historical-extract, analysis-status"
      contains: "analyze-session"
    - path: "get-shit-done/bin/historical-extract.js"
      provides: "Historical extraction from existing GSD project .planning/ directories"
      contains: "extractFromProject"
  key_links:
    - from: "get-shit-done/bin/gsd-tools.js"
      to: "get-shit-done/bin/session-analyzer.js"
      via: "require for analyze-session command"
      pattern: "session-analyzer"
    - from: "get-shit-done/bin/gsd-tools.js"
      to: "get-shit-done/bin/historical-extract.js"
      via: "require for historical-extract command"
      pattern: "historical-extract"
    - from: "get-shit-done/bin/historical-extract.js"
      to: "get-shit-done/bin/session-analyzer.js"
      via: "analyzeSession for each phase's content"
      pattern: "analyzeSession"
    - from: "get-shit-done/bin/historical-extract.js"
      to: "get-shit-done/bin/knowledge-writer.js"
      via: "storeInsights for persisting extracted knowledge"
      pattern: "storeInsights"
---

<objective>
Add CLI commands for manual session analysis, historical data mining from existing GSD projects, and analysis status reporting.

Purpose: Enables manual triggering of analysis (debugging, testing), bulk extraction from historical projects (locked decision #4), and visibility into what has been analyzed. The historical-extract command is critical for bootstrapping knowledge from existing work.

Output: Updated gsd-tools.js (3 new subcommands), historical-extract.js (project-level extraction)
</objective>

<execution_context>
@/Users/ollorin/.claude/get-shit-done/workflows/execute-plan.md
@/Users/ollorin/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/11-session-end-knowledge-extraction-implement-haiku-based-analysis-of-completed-sessions-to-extract-reasoning-patterns-and-decisions-beyond-keyword-matching/11-CONTEXT.md
@.planning/phases/11-session-end-knowledge-extraction-implement-haiku-based-analysis-of-completed-sessions-to-extract-reasoning-patterns-and-decisions-beyond-keyword-matching/11-01-SUMMARY.md
@.planning/phases/11-session-end-knowledge-extraction-implement-haiku-based-analysis-of-completed-sessions-to-extract-reasoning-patterns-and-decisions-beyond-keyword-matching/11-02-SUMMARY.md
@.planning/phases/11-session-end-knowledge-extraction-implement-haiku-based-analysis-of-completed-sessions-to-extract-reasoning-patterns-and-decisions-beyond-keyword-matching/11-03-SUMMARY.md
@get-shit-done/bin/gsd-tools.js
@get-shit-done/bin/session-analyzer.js
@get-shit-done/bin/session-quality-gates.js
@get-shit-done/bin/knowledge-writer.js
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create historical extraction module</name>
  <files>
    get-shit-done/bin/historical-extract.js
  </files>
  <action>
Create historical-extract.js (CommonJS) per locked decision #4:

**`extractFromProject(planningPath)`** - Main entry point. `planningPath` is absolute path to a project's `.planning/` directory:

1. **Discover completed phases:** Read ROADMAP.md from `planningPath/ROADMAP.md`. Parse phase entries. Identify completed phases (marked with `[x]` or having status "Complete" in the progress table). Skip incomplete phases per discretion recommendation.

2. **For each completed phase**, sequentially (not parallel, per discretion recommendation):
   a. Read phase files: ROADMAP.md section for that phase, all *-PLAN.md files, all *-SUMMARY.md files, VERIFICATION.md if exists
   b. Concatenate content into a "session transcript" format:
      - Format as timestamped entries similar to session JSONL: `[0] [phase-start] CONTEXT: Phase {N} goal: {goal}`
      - Each PLAN.md becomes `[{i}] PLAN: {plan objective and tasks}`
      - Each SUMMARY.md becomes `[{i}] COMPLETION: {summary of what was built, decisions made}`
      - VERIFICATION.md becomes `[{i}] VERIFICATION: {results}`
   c. Use `conversation_id = "phase-{phaseNumber}"` per locked decision #4 (treat each phase as one conversation)
   d. Pass formatted content to session-analyzer.js `analyzeSession()` to get extraction requests
   e. **Note:** Like session-analyzer.js, this prepares extraction requests for the calling workflow to execute via Task(). The function returns the prepared requests, not the results.

3. **Return structured result:**
   ```javascript
   {
     projectPath: planningPath,
     phasesFound: number,
     phasesCompleted: number,
     extractionRequests: [
       { phaseNumber: string, conversationId: string, requests: ExtractionRequest[] }
     ]
   }
   ```

**`formatPhaseAsTranscript(phaseFiles)`** - Helper that converts phase files into session-like transcript format.

**`discoverCompletedPhases(roadmapContent)`** - Parse ROADMAP.md to find completed phases. Returns array of `{number, name, goal}`.

Use CommonJS. Use fs/path for file reading. Parse ROADMAP.md with regex patterns matching existing roadmap-parser.js approach.
  </action>
  <verify>
    node -e "const h = require('./get-shit-done/bin/historical-extract.js'); console.log(Object.keys(h)); console.log(typeof h.extractFromProject === 'function');"
  </verify>
  <done>
    historical-extract.js reads completed phases from ROADMAP.md, formats plan/summary files as transcripts, prepares Haiku extraction requests with conversation_id per phase. Sequential processing. Returns structured extraction request arrays for Task() invocation by calling workflow.
  </done>
</task>

<task type="auto">
  <name>Task 2: Add CLI commands to gsd-tools.js</name>
  <files>
    get-shit-done/bin/gsd-tools.js
  </files>
  <action>
Add three new subcommands to gsd-tools.js. Follow existing gsd-tools.js patterns: parse args, lazy-require modules, JSON output.

**1. `analyze-session <session-file-path>`** subcommand:
- Accepts path to a session JSONL file (absolute or relative)
- Lazy-require session-analyzer.js, session-quality-gates.js, session-chunker.js
- Load entries via loadSessionJSONL pattern (read file, parse JSONL lines)
- Run quality gates: if shouldAnalyzeSession returns false, output `{status: "skipped", reason}` and exit
- Check re-analysis: if isAlreadyAnalyzed returns true, output `{status: "already_analyzed"}` and exit
- Prepare session: call prepareSessionForAnalysis for chunking
- Call analyzeSession to get extraction requests
- Output JSON: `{status: "ready", chunkCount, extractionRequests: [...]}`
- The extraction requests are designed for a GSD workflow to pass to Task() subagents

**2. `historical-extract <planning-path>`** subcommand:
- Accepts path to a project's .planning/ directory
- Lazy-require historical-extract.js
- Call extractFromProject(planningPath)
- Output JSON result with phases found, completed, and extraction requests
- If path doesn't exist or has no ROADMAP.md, output error JSON

**3. `analysis-status`** subcommand:
- Lazy-require session-quality-gates.js
- Call getAnalysisStats()
- Output JSON: `{totalAnalyzed, totalInsights, lastAnalysis, analysisLogPath}`
- If no analysis log exists, output `{totalAnalyzed: 0, totalInsights: 0, lastAnalysis: null}`

Add all three to the command help text at the top of gsd-tools.js in the appropriate section. Add them to the command dispatch switch/if chain following existing patterns.

Also add to the Usage comment block:
```
 * Session Analysis:
 *   analyze-session <path>           Prepare session for Haiku analysis
 *   historical-extract <path>        Extract knowledge from existing project
 *   analysis-status                  Show analysis statistics
```
  </action>
  <verify>
    node /Users/ollorin/get-shit-done/get-shit-done/bin/gsd-tools.js analysis-status 2>&1
  </verify>
  <done>
    gsd-tools.js has three new subcommands: analyze-session (prepares session for analysis), historical-extract (prepares historical project for analysis), analysis-status (reports analysis statistics). All output JSON. All follow existing gsd-tools patterns. Help text updated.
  </done>
</task>

</tasks>

<verification>
1. `node gsd-tools.js analyze-session /path/to/nonexistent.jsonl` returns error JSON gracefully
2. `node gsd-tools.js historical-extract /path/to/nonexistent/.planning` returns error JSON gracefully
3. `node gsd-tools.js analysis-status` returns JSON with totalAnalyzed field
4. `node -e "require('./get-shit-done/bin/historical-extract.js')"` loads without error
5. No imports of `@anthropic-ai/sdk` in any new or modified files
6. historical-extract uses conversation_id per phase (locked decision #4)
</verification>

<success_criteria>
- Manual analysis via CLI: `gsd-tools.js analyze-session` prepares any session file for analysis
- Historical mining: `gsd-tools.js historical-extract` reads completed phases and prepares extraction requests
- Status reporting: `gsd-tools.js analysis-status` shows what has been analyzed
- All analysis uses subscription-only Task() pattern (extraction requests returned for workflow invocation)
- Sequential historical processing (not parallel) per discretion recommendation
</success_criteria>

<output>
After completion, create `.planning/phases/11-session-end-knowledge-extraction-implement-haiku-based-analysis-of-completed-sessions-to-extract-reasoning-patterns-and-decisions-beyond-keyword-matching/11-04-SUMMARY.md`
</output>
