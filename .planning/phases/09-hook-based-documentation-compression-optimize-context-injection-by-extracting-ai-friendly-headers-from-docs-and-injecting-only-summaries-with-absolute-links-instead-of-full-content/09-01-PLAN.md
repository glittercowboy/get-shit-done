---
phase: 09-hook-based-documentation-compression
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - ~/.claude/get-shit-done/bin/compression/header-extractor.js
  - ~/.claude/get-shit-done/bin/compression/summary-generator.js
  - ~/.claude/get-shit-done/package.json
autonomous: true

must_haves:
  truths:
    - "Header extraction parses markdown structure and captures section previews"
    - "Summary generation achieves 60-70% token reduction vs original content"
    - "Frontmatter (tags, title, metadata) is preserved in summaries"
    - "Absolute file links are appended to compressed output"
  artifacts:
    - path: "~/.claude/get-shit-done/bin/compression/header-extractor.js"
      provides: "HeaderExtractor class with extractSummary method"
      exports: ["HeaderExtractor"]
    - path: "~/.claude/get-shit-done/bin/compression/summary-generator.js"
      provides: "SummaryGenerator with configurable strategies"
      exports: ["SummaryGenerator"]
    - path: "~/.claude/get-shit-done/package.json"
      provides: "markdown-it and gray-matter dependencies"
      contains: "markdown-it"
  key_links:
    - from: "header-extractor.js"
      to: "markdown-it"
      via: "require('markdown-it')"
      pattern: "new MarkdownIt"
    - from: "header-extractor.js"
      to: "gray-matter"
      via: "require('gray-matter')"
      pattern: "grayMatter\\(content\\)"
---

<objective>
Build the core header extraction and summary generation modules that both Task Context Skill and GSD Doc Compression will use.

Purpose: Create shared infrastructure for 60-70% token reduction through deterministic header-based compression.
Output: Two modules (header-extractor.js, summary-generator.js) with dependencies installed.
</objective>

<execution_context>
@/Users/ollorin/.claude/get-shit-done/workflows/execute-plan.md
@/Users/ollorin/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/09-hook-based-documentation-compression-optimize-context-injection-by-extracting-ai-friendly-headers-from-docs-and-injecting-only-summaries-with-absolute-links-instead-of-full-content/09-RESEARCH.md

Reference existing routing infrastructure:
@~/.claude/get-shit-done/bin/gsd-tools.js (lines 2469-2635 - extractKeywords, buildContextIndex, matchContextDocs)
</context>

<tasks>

<task type="auto">
  <name>Task 1: Install markdown parsing dependencies</name>
  <files>~/.claude/get-shit-done/package.json</files>
  <action>
  Install markdown-it and gray-matter dependencies:

  ```bash
  cd ~/.claude/get-shit-done && npm install markdown-it@^14.1.0 gray-matter@^4.0.3
  ```

  Verify package.json includes both dependencies with correct versions.
  These are the ONLY dependencies needed for Phase 9 core functionality.
  Do NOT install optional packages (@anthropic-ai/tokenizer, wink-bm25-text-search) yet.
  </action>
  <verify>Run `npm ls markdown-it gray-matter` to confirm installation</verify>
  <done>Both packages appear in dependencies with versions ^14.1.0 and ^4.0.3 respectively</done>
</task>

<task type="auto">
  <name>Task 2: Create HeaderExtractor class</name>
  <files>~/.claude/get-shit-done/bin/compression/header-extractor.js</files>
  <action>
  Create the header-extractor.js module with:

  1. **HeaderExtractor class** with constructor that initializes markdown-it parser

  2. **extractSummary(markdownContent, absolutePath)** method that:
     - Uses gray-matter to parse frontmatter (tags, title, description)
     - Uses markdown-it to tokenize content
     - Iterates tokens to find headers (heading_open type, h1-h6 via tag property)
     - Captures first paragraph after each header (max 300 chars)
     - Builds summary markdown with:
       - Preserved frontmatter (YAML format)
       - H1 title + first paragraph
       - H2-H6 sections with title + preview + "..."
       - Footer with absolute file link: `**Full documentation:** [View complete file](file://${absolutePath})`
     - Returns: `{ summary, sections: number, frontmatter: object }`

  3. **extractTableOfContents(markdownContent)** method that:
     - Returns hierarchical array of headers: `[{ level, title, children }]`
     - Used for quick doc overview without content

  Handle edge cases:
  - Empty content (return minimal summary with just file link)
  - No headers (return full content if < 500 chars, else truncate)
  - Nested code blocks (skip inline tokens within fenced_code)
  - Bullet lists after headers (capture first 3 bullets as preview)

  Pattern from research:
  ```javascript
  const MarkdownIt = require('markdown-it');
  const grayMatter = require('gray-matter');

  class HeaderExtractor {
    constructor() {
      this.md = new MarkdownIt();
    }

    extractSummary(markdownContent, absolutePath) {
      const { data: frontmatter, content } = grayMatter(markdownContent);
      const tokens = this.md.parse(content, {});
      // ... implementation
    }
  }
  ```
  </action>
  <verify>
  Create a test file and run:
  ```bash
  node -e "
    const { HeaderExtractor } = require('$HOME/.claude/get-shit-done/bin/compression/header-extractor');
    const ex = new HeaderExtractor();
    const result = ex.extractSummary('# Title\n\nFirst paragraph.\n\n## Section\n\nContent here.', '/test/file.md');
    console.log(JSON.stringify(result, null, 2));
  "
  ```
  </verify>
  <done>extractSummary returns object with summary (markdown string), sections count, and frontmatter. Summary contains headers with previews and file link footer.</done>
</task>

<task type="auto">
  <name>Task 3: Create SummaryGenerator with strategies</name>
  <files>~/.claude/get-shit-done/bin/compression/summary-generator.js</files>
  <action>
  Create summary-generator.js that provides different summary strategies:

  1. **SummaryGenerator class** with constructor accepting options:
     - `strategy`: 'header-extraction' | 'first-n-paragraphs' | 'bullets-only'
     - `maxPreviewChars`: number (default 300)
     - `maxBullets`: number (default 3)
     - `includeCodeBlocks`: boolean (default false)

  2. **generate(markdownContent, absolutePath)** method:
     - Uses HeaderExtractor internally
     - Applies strategy-specific post-processing
     - Returns: `{ summary, originalLength, summaryLength, reductionPercent }`

  3. **Strategy implementations:**
     - `header-extraction`: Use HeaderExtractor.extractSummary as-is (default)
     - `first-n-paragraphs`: Extract first N paragraphs only (ignores structure)
     - `bullets-only`: Extract only bullet point lists (for action-oriented docs)

  4. **Static methods:**
     - `estimateTokens(text)`: Character-based rough estimate (chars / 4)
     - `calculateReduction(original, summary)`: Returns percentage reduction

  Integration pattern:
  ```javascript
  const { HeaderExtractor } = require('./header-extractor');

  class SummaryGenerator {
    constructor(options = {}) {
      this.strategy = options.strategy || 'header-extraction';
      this.extractor = new HeaderExtractor();
    }

    generate(content, path) {
      // Strategy-based generation
    }
  }
  ```

  Export both classes for flexibility.
  </action>
  <verify>
  Run:
  ```bash
  node -e "
    const { SummaryGenerator } = require('$HOME/.claude/get-shit-done/bin/compression/summary-generator');
    const gen = new SummaryGenerator({ strategy: 'header-extraction' });
    const result = gen.generate('# Test\n\nLong paragraph here with lots of text...'.repeat(50), '/test/file.md');
    console.log('Reduction:', result.reductionPercent, '%');
  "
  ```
  </verify>
  <done>SummaryGenerator returns reduction percentage >= 60% for typical documentation files. Multiple strategies available.</done>
</task>

</tasks>

<verification>
Run the following to verify the complete implementation:

```bash
# 1. Check dependencies installed
cd ~/.claude/get-shit-done && npm ls markdown-it gray-matter

# 2. Test header extraction on real file
node -e "
  const { HeaderExtractor } = require('$HOME/.claude/get-shit-done/bin/compression/header-extractor');
  const fs = require('fs');
  const ex = new HeaderExtractor();
  const content = fs.readFileSync('$HOME/get-shit-done/.planning/ROADMAP.md', 'utf-8');
  const result = ex.extractSummary(content, '$HOME/get-shit-done/.planning/ROADMAP.md');
  console.log('Sections:', result.sections);
  console.log('Summary length:', result.summary.length);
  console.log('Original length:', content.length);
  console.log('Reduction:', ((1 - result.summary.length / content.length) * 100).toFixed(1), '%');
"

# 3. Test summary generator strategies
node -e "
  const { SummaryGenerator } = require('$HOME/.claude/get-shit-done/bin/compression/summary-generator');
  const fs = require('fs');
  const gen = new SummaryGenerator();
  const content = fs.readFileSync('$HOME/get-shit-done/.planning/ROADMAP.md', 'utf-8');
  const result = gen.generate(content, '$HOME/get-shit-done/.planning/ROADMAP.md');
  console.log('Strategy:', 'header-extraction');
  console.log('Reduction:', result.reductionPercent, '%');
"
```

Expected: Reduction percentage >= 60% on ROADMAP.md
</verification>

<success_criteria>
1. markdown-it and gray-matter installed in package.json
2. header-extractor.js exports HeaderExtractor class
3. summary-generator.js exports SummaryGenerator class
4. extractSummary returns properly formatted markdown summary with file link
5. Reduction percentage >= 60% on typical GSD documentation files
6. All edge cases handled (empty content, no headers, nested code blocks)
</success_criteria>

<output>
After completion, create `.planning/phases/09-hook-based-documentation-compression-optimize-context-injection-by-extracting-ai-friendly-headers-from-docs-and-injecting-only-summaries-with-absolute-links-instead-of-full-content/09-01-SUMMARY.md`
</output>
